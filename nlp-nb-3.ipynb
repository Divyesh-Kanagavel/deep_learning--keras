{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-25T14:03:11.685860Z","iopub.execute_input":"2023-01-25T14:03:11.686938Z","iopub.status.idle":"2023-01-25T14:03:23.291115Z","shell.execute_reply.started":"2023-01-25T14:03:11.686853Z","shell.execute_reply":"2023-01-25T14:03:23.289702Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"from fastbook import *","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.295028Z","iopub.execute_input":"2023-01-25T14:03:23.295389Z","iopub.status.idle":"2023-01-25T14:03:23.302209Z","shell.execute_reply.started":"2023-01-25T14:03:23.295357Z","shell.execute_reply":"2023-01-25T14:03:23.301202Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"In this notebooks, the nut and bolts of the natural language models are discussed- we know how to pre-train a language model, use the high-level and mid-level API for flexibity. Understanding what happens beneath the hood will help understand even better.","metadata":{}},{"cell_type":"markdown","source":"To try out the efficacy of a new algorithm or when we try to embark on a learning journey in ML, start with a simple dataset , easy to train and verify. Starting with complicated datasets is a hindrance as the complexity of the project increases manifold.","metadata":{}},{"cell_type":"code","source":"from fastai.text.all import *\npath = untar_data(URLs.HUMAN_NUMBERS)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.304188Z","iopub.execute_input":"2023-01-25T14:03:23.304571Z","iopub.status.idle":"2023-01-25T14:03:23.317077Z","shell.execute_reply.started":"2023-01-25T14:03:23.304534Z","shell.execute_reply":"2023-01-25T14:03:23.315904Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"This is a simple dataset which has first 10000 numbers written in English. ","metadata":{}},{"cell_type":"code","source":"Path.BASE_PATH = path\npath.ls()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.319232Z","iopub.execute_input":"2023-01-25T14:03:23.319621Z","iopub.status.idle":"2023-01-25T14:03:23.330820Z","shell.execute_reply.started":"2023-01-25T14:03:23.319584Z","shell.execute_reply":"2023-01-25T14:03:23.329802Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"(#2) [Path('valid.txt'),Path('train.txt')]"},"metadata":{}}]},{"cell_type":"code","source":"lines = L()\nwith open(path/'train.txt') as f: lines+=L(*f.readlines())\nwith open(path/'valid.txt') as f: lines+=L(*f.readlines())\n\nlines","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.334710Z","iopub.execute_input":"2023-01-25T14:03:23.335328Z","iopub.status.idle":"2023-01-25T14:03:23.348207Z","shell.execute_reply.started":"2023-01-25T14:03:23.335299Z","shell.execute_reply":"2023-01-25T14:03:23.347117Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"},"metadata":{}}]},{"cell_type":"markdown","source":"Step1 : concatenation of the numbers in the list to a single big string, we use ' . ' as a separator to move from one number to next","metadata":{}},{"cell_type":"code","source":"text = ' . '.join(l.strip() for l in lines)\nlen(text)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.349975Z","iopub.execute_input":"2023-01-25T14:03:23.350318Z","iopub.status.idle":"2023-01-25T14:03:23.360042Z","shell.execute_reply.started":"2023-01-25T14:03:23.350285Z","shell.execute_reply":"2023-01-25T14:03:23.358948Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"365478"},"metadata":{}}]},{"cell_type":"markdown","source":"we could use a tokenizer like spacy, but since this is a simple dataset of only numbers in word form, a simple space based tokenizer is enough","metadata":{}},{"cell_type":"code","source":"tokens = text.split(' ')","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.361516Z","iopub.execute_input":"2023-01-25T14:03:23.362253Z","iopub.status.idle":"2023-01-25T14:03:23.376381Z","shell.execute_reply.started":"2023-01-25T14:03:23.362215Z","shell.execute_reply":"2023-01-25T14:03:23.375340Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"tokens[:10]","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.378056Z","iopub.execute_input":"2023-01-25T14:03:23.378479Z","iopub.status.idle":"2023-01-25T14:03:23.389916Z","shell.execute_reply.started":"2023-01-25T14:03:23.378446Z","shell.execute_reply":"2023-01-25T14:03:23.388908Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"},"metadata":{}}]},{"cell_type":"code","source":"tokens[63093]","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.393125Z","iopub.execute_input":"2023-01-25T14:03:23.393414Z","iopub.status.idle":"2023-01-25T14:03:23.402907Z","shell.execute_reply.started":"2023-01-25T14:03:23.393379Z","shell.execute_reply":"2023-01-25T14:03:23.401910Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"'ninety'"},"metadata":{}}]},{"cell_type":"code","source":"vocab = L(*tokens).unique()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.404414Z","iopub.execute_input":"2023-01-25T14:03:23.404974Z","iopub.status.idle":"2023-01-25T14:03:23.423727Z","shell.execute_reply.started":"2023-01-25T14:03:23.404939Z","shell.execute_reply":"2023-01-25T14:03:23.422517Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"vocab","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.425633Z","iopub.execute_input":"2023-01-25T14:03:23.426588Z","iopub.status.idle":"2023-01-25T14:03:23.433168Z","shell.execute_reply.started":"2023-01-25T14:03:23.426549Z","shell.execute_reply":"2023-01-25T14:03:23.431942Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"},"metadata":{}}]},{"cell_type":"code","source":"print(vocab)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.434817Z","iopub.execute_input":"2023-01-25T14:03:23.435300Z","iopub.status.idle":"2023-01-25T14:03:23.442437Z","shell.execute_reply.started":"2023-01-25T14:03:23.435263Z","shell.execute_reply":"2023-01-25T14:03:23.441311Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"['one', '.', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety', 'hundred', 'thousand']\n","output_type":"stream"}]},{"cell_type":"code","source":"word2index = {w:i for i,w in enumerate(vocab)}\nnums = L(word2index[i] for i in tokens)\nlen(nums)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.444487Z","iopub.execute_input":"2023-01-25T14:03:23.446050Z","iopub.status.idle":"2023-01-25T14:03:23.462197Z","shell.execute_reply.started":"2023-01-25T14:03:23.446020Z","shell.execute_reply":"2023-01-25T14:03:23.461011Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"63095"},"metadata":{}}]},{"cell_type":"markdown","source":"Language model from scratch - we now have the tokenized and numericalized text data","metadata":{}},{"cell_type":"code","source":"print(L((tokens[i:i+3],tokens[i+3]) for i in range(0,len(tokens)-4,3))[:100])\n  ","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.468587Z","iopub.execute_input":"2023-01-25T14:03:23.469222Z","iopub.status.idle":"2023-01-25T14:03:23.495876Z","shell.execute_reply.started":"2023-01-25T14:03:23.469193Z","shell.execute_reply":"2023-01-25T14:03:23.494558Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"[(['one', '.', 'two'], '.'), (['.', 'three', '.'], 'four'), (['four', '.', 'five'], '.'), (['.', 'six', '.'], 'seven'), (['seven', '.', 'eight'], '.'), (['.', 'nine', '.'], 'ten'), (['ten', '.', 'eleven'], '.'), (['.', 'twelve', '.'], 'thirteen'), (['thirteen', '.', 'fourteen'], '.'), (['.', 'fifteen', '.'], 'sixteen'), (['sixteen', '.', 'seventeen'], '.'), (['.', 'eighteen', '.'], 'nineteen'), (['nineteen', '.', 'twenty'], '.'), (['.', 'twenty', 'one'], '.'), (['.', 'twenty', 'two'], '.'), (['.', 'twenty', 'three'], '.'), (['.', 'twenty', 'four'], '.'), (['.', 'twenty', 'five'], '.'), (['.', 'twenty', 'six'], '.'), (['.', 'twenty', 'seven'], '.'), (['.', 'twenty', 'eight'], '.'), (['.', 'twenty', 'nine'], '.'), (['.', 'thirty', '.'], 'thirty'), (['thirty', 'one', '.'], 'thirty'), (['thirty', 'two', '.'], 'thirty'), (['thirty', 'three', '.'], 'thirty'), (['thirty', 'four', '.'], 'thirty'), (['thirty', 'five', '.'], 'thirty'), (['thirty', 'six', '.'], 'thirty'), (['thirty', 'seven', '.'], 'thirty'), (['thirty', 'eight', '.'], 'thirty'), (['thirty', 'nine', '.'], 'forty'), (['forty', '.', 'forty'], 'one'), (['one', '.', 'forty'], 'two'), (['two', '.', 'forty'], 'three'), (['three', '.', 'forty'], 'four'), (['four', '.', 'forty'], 'five'), (['five', '.', 'forty'], 'six'), (['six', '.', 'forty'], 'seven'), (['seven', '.', 'forty'], 'eight'), (['eight', '.', 'forty'], 'nine'), (['nine', '.', 'fifty'], '.'), (['.', 'fifty', 'one'], '.'), (['.', 'fifty', 'two'], '.'), (['.', 'fifty', 'three'], '.'), (['.', 'fifty', 'four'], '.'), (['.', 'fifty', 'five'], '.'), (['.', 'fifty', 'six'], '.'), (['.', 'fifty', 'seven'], '.'), (['.', 'fifty', 'eight'], '.'), (['.', 'fifty', 'nine'], '.'), (['.', 'sixty', '.'], 'sixty'), (['sixty', 'one', '.'], 'sixty'), (['sixty', 'two', '.'], 'sixty'), (['sixty', 'three', '.'], 'sixty'), (['sixty', 'four', '.'], 'sixty'), (['sixty', 'five', '.'], 'sixty'), (['sixty', 'six', '.'], 'sixty'), (['sixty', 'seven', '.'], 'sixty'), (['sixty', 'eight', '.'], 'sixty'), (['sixty', 'nine', '.'], 'seventy'), (['seventy', '.', 'seventy'], 'one'), (['one', '.', 'seventy'], 'two'), (['two', '.', 'seventy'], 'three'), (['three', '.', 'seventy'], 'four'), (['four', '.', 'seventy'], 'five'), (['five', '.', 'seventy'], 'six'), (['six', '.', 'seventy'], 'seven'), (['seven', '.', 'seventy'], 'eight'), (['eight', '.', 'seventy'], 'nine'), (['nine', '.', 'eighty'], '.'), (['.', 'eighty', 'one'], '.'), (['.', 'eighty', 'two'], '.'), (['.', 'eighty', 'three'], '.'), (['.', 'eighty', 'four'], '.'), (['.', 'eighty', 'five'], '.'), (['.', 'eighty', 'six'], '.'), (['.', 'eighty', 'seven'], '.'), (['.', 'eighty', 'eight'], '.'), (['.', 'eighty', 'nine'], '.'), (['.', 'ninety', '.'], 'ninety'), (['ninety', 'one', '.'], 'ninety'), (['ninety', 'two', '.'], 'ninety'), (['ninety', 'three', '.'], 'ninety'), (['ninety', 'four', '.'], 'ninety'), (['ninety', 'five', '.'], 'ninety'), (['ninety', 'six', '.'], 'ninety'), (['ninety', 'seven', '.'], 'ninety'), (['ninety', 'eight', '.'], 'ninety'), (['ninety', 'nine', '.'], 'one'), (['one', 'hundred', '.'], 'one'), (['one', 'hundred', 'one'], '.'), (['.', 'one', 'hundred'], 'two'), (['two', '.', 'one'], 'hundred'), (['hundred', 'three', '.'], 'one'), (['one', 'hundred', 'four'], '.'), (['.', 'one', 'hundred'], 'five'), (['five', '.', 'one'], 'hundred'), (['hundred', 'six', '.'], 'one'), (['one', 'hundred', 'seven'], '.')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Given three words in sequence, predict the next word in the sequence. The dataset is curated in a way, three words in sequence form the independent variable and fourth word is taken as the dependent variable. The same could be done in  numerical form as follows: ","metadata":{}},{"cell_type":"code","source":"seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.497303Z","iopub.execute_input":"2023-01-25T14:03:23.498250Z","iopub.status.idle":"2023-01-25T14:03:23.967523Z","shell.execute_reply.started":"2023-01-25T14:03:23.498210Z","shell.execute_reply":"2023-01-25T14:03:23.966508Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"print(seqs[:200])","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.969955Z","iopub.execute_input":"2023-01-25T14:03:23.970567Z","iopub.status.idle":"2023-01-25T14:03:23.988723Z","shell.execute_reply.started":"2023-01-25T14:03:23.970527Z","shell.execute_reply":"2023-01-25T14:03:23.987772Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"[(tensor([0, 1, 2]), 1), (tensor([1, 3, 1]), 4), (tensor([4, 1, 5]), 1), (tensor([1, 6, 1]), 7), (tensor([7, 1, 8]), 1), (tensor([1, 9, 1]), 10), (tensor([10,  1, 11]), 1), (tensor([ 1, 12,  1]), 13), (tensor([13,  1, 14]), 1), (tensor([ 1, 15,  1]), 16), (tensor([16,  1, 17]), 1), (tensor([ 1, 18,  1]), 19), (tensor([19,  1, 20]), 1), (tensor([ 1, 20,  0]), 1), (tensor([ 1, 20,  2]), 1), (tensor([ 1, 20,  3]), 1), (tensor([ 1, 20,  4]), 1), (tensor([ 1, 20,  5]), 1), (tensor([ 1, 20,  6]), 1), (tensor([ 1, 20,  7]), 1), (tensor([ 1, 20,  8]), 1), (tensor([ 1, 20,  9]), 1), (tensor([ 1, 21,  1]), 21), (tensor([21,  0,  1]), 21), (tensor([21,  2,  1]), 21), (tensor([21,  3,  1]), 21), (tensor([21,  4,  1]), 21), (tensor([21,  5,  1]), 21), (tensor([21,  6,  1]), 21), (tensor([21,  7,  1]), 21), (tensor([21,  8,  1]), 21), (tensor([21,  9,  1]), 22), (tensor([22,  1, 22]), 0), (tensor([ 0,  1, 22]), 2), (tensor([ 2,  1, 22]), 3), (tensor([ 3,  1, 22]), 4), (tensor([ 4,  1, 22]), 5), (tensor([ 5,  1, 22]), 6), (tensor([ 6,  1, 22]), 7), (tensor([ 7,  1, 22]), 8), (tensor([ 8,  1, 22]), 9), (tensor([ 9,  1, 23]), 1), (tensor([ 1, 23,  0]), 1), (tensor([ 1, 23,  2]), 1), (tensor([ 1, 23,  3]), 1), (tensor([ 1, 23,  4]), 1), (tensor([ 1, 23,  5]), 1), (tensor([ 1, 23,  6]), 1), (tensor([ 1, 23,  7]), 1), (tensor([ 1, 23,  8]), 1), (tensor([ 1, 23,  9]), 1), (tensor([ 1, 24,  1]), 24), (tensor([24,  0,  1]), 24), (tensor([24,  2,  1]), 24), (tensor([24,  3,  1]), 24), (tensor([24,  4,  1]), 24), (tensor([24,  5,  1]), 24), (tensor([24,  6,  1]), 24), (tensor([24,  7,  1]), 24), (tensor([24,  8,  1]), 24), (tensor([24,  9,  1]), 25), (tensor([25,  1, 25]), 0), (tensor([ 0,  1, 25]), 2), (tensor([ 2,  1, 25]), 3), (tensor([ 3,  1, 25]), 4), (tensor([ 4,  1, 25]), 5), (tensor([ 5,  1, 25]), 6), (tensor([ 6,  1, 25]), 7), (tensor([ 7,  1, 25]), 8), (tensor([ 8,  1, 25]), 9), (tensor([ 9,  1, 26]), 1), (tensor([ 1, 26,  0]), 1), (tensor([ 1, 26,  2]), 1), (tensor([ 1, 26,  3]), 1), (tensor([ 1, 26,  4]), 1), (tensor([ 1, 26,  5]), 1), (tensor([ 1, 26,  6]), 1), (tensor([ 1, 26,  7]), 1), (tensor([ 1, 26,  8]), 1), (tensor([ 1, 26,  9]), 1), (tensor([ 1, 27,  1]), 27), (tensor([27,  0,  1]), 27), (tensor([27,  2,  1]), 27), (tensor([27,  3,  1]), 27), (tensor([27,  4,  1]), 27), (tensor([27,  5,  1]), 27), (tensor([27,  6,  1]), 27), (tensor([27,  7,  1]), 27), (tensor([27,  8,  1]), 27), (tensor([27,  9,  1]), 0), (tensor([ 0, 28,  1]), 0), (tensor([ 0, 28,  0]), 1), (tensor([ 1,  0, 28]), 2), (tensor([2, 1, 0]), 28), (tensor([28,  3,  1]), 0), (tensor([ 0, 28,  4]), 1), (tensor([ 1,  0, 28]), 5), (tensor([5, 1, 0]), 28), (tensor([28,  6,  1]), 0), (tensor([ 0, 28,  7]), 1), (tensor([ 1,  0, 28]), 8), (tensor([8, 1, 0]), 28), (tensor([28,  9,  1]), 0), (tensor([ 0, 28, 10]), 1), (tensor([ 1,  0, 28]), 11), (tensor([11,  1,  0]), 28), (tensor([28, 12,  1]), 0), (tensor([ 0, 28, 13]), 1), (tensor([ 1,  0, 28]), 14), (tensor([14,  1,  0]), 28), (tensor([28, 15,  1]), 0), (tensor([ 0, 28, 16]), 1), (tensor([ 1,  0, 28]), 17), (tensor([17,  1,  0]), 28), (tensor([28, 18,  1]), 0), (tensor([ 0, 28, 19]), 1), (tensor([ 1,  0, 28]), 20), (tensor([20,  1,  0]), 28), (tensor([28, 20,  0]), 1), (tensor([ 1,  0, 28]), 20), (tensor([20,  2,  1]), 0), (tensor([ 0, 28, 20]), 3), (tensor([3, 1, 0]), 28), (tensor([28, 20,  4]), 1), (tensor([ 1,  0, 28]), 20), (tensor([20,  5,  1]), 0), (tensor([ 0, 28, 20]), 6), (tensor([6, 1, 0]), 28), (tensor([28, 20,  7]), 1), (tensor([ 1,  0, 28]), 20), (tensor([20,  8,  1]), 0), (tensor([ 0, 28, 20]), 9), (tensor([9, 1, 0]), 28), (tensor([28, 21,  1]), 0), (tensor([ 0, 28, 21]), 0), (tensor([0, 1, 0]), 28), (tensor([28, 21,  2]), 1), (tensor([ 1,  0, 28]), 21), (tensor([21,  3,  1]), 0), (tensor([ 0, 28, 21]), 4), (tensor([4, 1, 0]), 28), (tensor([28, 21,  5]), 1), (tensor([ 1,  0, 28]), 21), (tensor([21,  6,  1]), 0), (tensor([ 0, 28, 21]), 7), (tensor([7, 1, 0]), 28), (tensor([28, 21,  8]), 1), (tensor([ 1,  0, 28]), 21), (tensor([21,  9,  1]), 0), (tensor([ 0, 28, 22]), 1), (tensor([ 1,  0, 28]), 22), (tensor([22,  0,  1]), 0), (tensor([ 0, 28, 22]), 2), (tensor([2, 1, 0]), 28), (tensor([28, 22,  3]), 1), (tensor([ 1,  0, 28]), 22), (tensor([22,  4,  1]), 0), (tensor([ 0, 28, 22]), 5), (tensor([5, 1, 0]), 28), (tensor([28, 22,  6]), 1), (tensor([ 1,  0, 28]), 22), (tensor([22,  7,  1]), 0), (tensor([ 0, 28, 22]), 8), (tensor([8, 1, 0]), 28), (tensor([28, 22,  9]), 1), (tensor([ 1,  0, 28]), 23), (tensor([23,  1,  0]), 28), (tensor([28, 23,  0]), 1), (tensor([ 1,  0, 28]), 23), (tensor([23,  2,  1]), 0), (tensor([ 0, 28, 23]), 3), (tensor([3, 1, 0]), 28), (tensor([28, 23,  4]), 1), (tensor([ 1,  0, 28]), 23), (tensor([23,  5,  1]), 0), (tensor([ 0, 28, 23]), 6), (tensor([6, 1, 0]), 28), (tensor([28, 23,  7]), 1), (tensor([ 1,  0, 28]), 23), (tensor([23,  8,  1]), 0), (tensor([ 0, 28, 23]), 9), (tensor([9, 1, 0]), 28), (tensor([28, 24,  1]), 0), (tensor([ 0, 28, 24]), 0), (tensor([0, 1, 0]), 28), (tensor([28, 24,  2]), 1), (tensor([ 1,  0, 28]), 24), (tensor([24,  3,  1]), 0), (tensor([ 0, 28, 24]), 4), (tensor([4, 1, 0]), 28), (tensor([28, 24,  5]), 1), (tensor([ 1,  0, 28]), 24), (tensor([24,  6,  1]), 0), (tensor([ 0, 28, 24]), 7), (tensor([7, 1, 0]), 28), (tensor([28, 24,  8]), 1), (tensor([ 1,  0, 28]), 24), (tensor([24,  9,  1]), 0), (tensor([ 0, 28, 25]), 1), (tensor([ 1,  0, 28]), 25)]\n","output_type":"stream"}]},{"cell_type":"code","source":"bs = 64\ncut = int(len(seqs) * 0.8)\ndls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.991216Z","iopub.execute_input":"2023-01-25T14:03:23.991502Z","iopub.status.idle":"2023-01-25T14:03:23.998035Z","shell.execute_reply.started":"2023-01-25T14:03:23.991475Z","shell.execute_reply":"2023-01-25T14:03:23.996939Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"The neural network architure used is a simple three layer model which has layers consisting of embedding to pick the index according to the word's position in the vocab. The first layer will have just the embedding of the first word, second layer will have embedding of second word + activation of the first word , third layer has embedding of third word + activation of the first+second","metadata":{}},{"cell_type":"markdown","source":"Another tweak is that the weight matrix for each of the layers correspinding to the three words are the same. the weight matrix is independent of position -> it only encodes probability of next word given a word. This word-word encoding does not depend on position.","metadata":{}},{"cell_type":"code","source":"# model built on pytorch\nclass LMModel1(Module):\n    def __init__(self,vocab_sz ,n_hidden):\n        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n        self.h_h = nn.Linear(n_hidden,n_hidden)\n        self.h_o = nn.Linear(n_hidden,vocab_sz)\n        \n    def forward(self,x):\n        h = F.relu(self.h_h(self.i_h(x[:,0])))\n        h = h + self.i_h(x[:,1])\n        h = F.relu(self.h_h(h))\n        h = h + self.i_h(x[:,2])\n        h = F.relu(self.h_h(h))\n        return self.h_o(h)\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:23.999606Z","iopub.execute_input":"2023-01-25T14:03:24.000401Z","iopub.status.idle":"2023-01-25T14:03:24.010891Z","shell.execute_reply.started":"2023-01-25T14:03:24.000356Z","shell.execute_reply":"2023-01-25T14:03:24.009811Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"learn = Learner(dls,LMModel1(len(vocab), 64),loss_func=F.cross_entropy,metrics=accuracy )\nlearn.fit_one_cycle(4,1e-3)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:24.014398Z","iopub.execute_input":"2023-01-25T14:03:24.014713Z","iopub.status.idle":"2023-01-25T14:03:32.364258Z","shell.execute_reply.started":"2023-01-25T14:03:24.014655Z","shell.execute_reply":"2023-01-25T14:03:32.362964Z"},"trusted":true},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.816107</td>\n      <td>1.899504</td>\n      <td>0.463275</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.413302</td>\n      <td>1.750920</td>\n      <td>0.468267</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.419951</td>\n      <td>1.615062</td>\n      <td>0.486095</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.384168</td>\n      <td>1.608317</td>\n      <td>0.495365</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"n,counts = 0,torch.zeros(len(vocab))\nfor x,y in dls.valid:\n    n+=y.shape[0]\n    for i in range_of(vocab) : counts[i] += (y == i).long().sum()\nidx = torch.argmax(counts)\nidx,vocab[idx.item()], counts[idx].item()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:32.366031Z","iopub.execute_input":"2023-01-25T14:03:32.367199Z","iopub.status.idle":"2023-01-25T14:03:32.641028Z","shell.execute_reply.started":"2023-01-25T14:03:32.367153Z","shell.execute_reply":"2023-01-25T14:03:32.639895Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"(tensor(29), 'thousand', 638.0)"},"metadata":{}}]},{"cell_type":"markdown","source":"first recurrent neural network\n","metadata":{}},{"cell_type":"code","source":"class LMModel2(Module):\n    def __init__(self, vocab_sz, n_hidden):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n        self.h_h = nn.Linear(n_hidden, n_hidden)     \n        self.h_o = nn.Linear(n_hidden,vocab_sz)\n        \n    def forward(self, x):\n        h = 0\n        for i in range(3):\n            h = h + self.i_h(x[:,i])\n            h = F.relu(self.h_h(h))\n        return self.h_o(h)\n     ","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:32.643094Z","iopub.execute_input":"2023-01-25T14:03:32.643517Z","iopub.status.idle":"2023-01-25T14:03:32.652119Z","shell.execute_reply.started":"2023-01-25T14:03:32.643473Z","shell.execute_reply":"2023-01-25T14:03:32.651055Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n                metrics=accuracy)\nlearn.fit_one_cycle(4, 1e-3)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:32.653626Z","iopub.execute_input":"2023-01-25T14:03:32.654603Z","iopub.status.idle":"2023-01-25T14:03:40.973486Z","shell.execute_reply.started":"2023-01-25T14:03:32.654561Z","shell.execute_reply":"2023-01-25T14:03:40.972123Z"},"trusted":true},"execution_count":90,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.821032</td>\n      <td>1.857483</td>\n      <td>0.467554</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.406928</td>\n      <td>1.751597</td>\n      <td>0.468029</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.412491</td>\n      <td>1.673440</td>\n      <td>0.490373</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.368348</td>\n      <td>1.620943</td>\n      <td>0.493463</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"RNN is not a new architecture , it is this for loop based neural netwrk where activations of layers are placed inside for loop","metadata":{}},{"cell_type":"markdown","source":"Some problems with above implementation:\n1. h = 0 for every input sequence - for the current example, the sequence is short (only three words),but in the original examples, we might have to parse long sequences. \n2. only fourth word is predicted given the first three words - why not predict second,third,fourth given first second third","metadata":{}},{"cell_type":"markdown","source":"each time we get a new word, h is set to 0, so we lose all the information from the previous words. Instead we could preserve the value of h. This introduces another subtle problem. if there are 10,000 words in the dataset, we will have 10,000 layer networks. so, when we calculate gradients, we have to back-propagate from 10000th layer to layer 0, with this network,, not even 1 mini batch can be processed. Instead, only last three layers are used for calculating the gradients.","metadata":{}},{"cell_type":"code","source":"class LMModel3(Module):\n    def __init__(self,vocab_sz,n_hidden):\n        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n        self.h_h = nn.Linear(n_hidden,n_hidden)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n        self.h = 0\n    \n    def forward(self,x):\n        for i in range(3):\n            self.h = self.h + self.i_h(x[:,i])\n            self.h = F.relu(self.h_h(self.h))\n        out = self.h_o(self.h)\n        self.h = self.h.detach()  # to prevent back prop to previous layers\n        \n        return out\n    def reset(self) : self.h=0\n            \n            \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:40.981534Z","iopub.execute_input":"2023-01-25T14:03:40.981915Z","iopub.status.idle":"2023-01-25T14:03:40.996281Z","shell.execute_reply.started":"2023-01-25T14:03:40.981841Z","shell.execute_reply":"2023-01-25T14:03:40.995114Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"The model will have same activations for different sequence lengths, the gradients will be calculated only for the last sequence and not the whole stream to avoid memory overhead and computational problems.\nThis approach is called Backpropagation through time (BPTT). ","metadata":{}},{"cell_type":"markdown","source":"for this model, the dataset is to be modeled in a certain way. the dataset is split into batches of size 64.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"bs = 64\nm = len(seqs) // bs\nm,bs,len(seqs)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:41.001268Z","iopub.execute_input":"2023-01-25T14:03:41.002175Z","iopub.status.idle":"2023-01-25T14:03:41.015263Z","shell.execute_reply.started":"2023-01-25T14:03:41.001981Z","shell.execute_reply":"2023-01-25T14:03:41.014054Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"(328, 64, 21031)"},"metadata":{}}]},{"cell_type":"code","source":"def group_chunks(ds,bs):\n    m = len(ds) // bs\n    new_ds = L()\n    for i in range(m):new_ds += L(ds[i+m*j] for j in range(bs))\n    return new_ds","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:41.019478Z","iopub.execute_input":"2023-01-25T14:03:41.019762Z","iopub.status.idle":"2023-01-25T14:03:41.028616Z","shell.execute_reply.started":"2023-01-25T14:03:41.019735Z","shell.execute_reply":"2023-01-25T14:03:41.026927Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"#Splitting into train and test\ncut = int(len(seqs)*0.8)\ndls = DataLoaders.from_dsets(group_chunks(seqs[:cut],bs),group_chunks(seqs[cut:],bs),bs=bs,drop_last=True,shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:41.030268Z","iopub.execute_input":"2023-01-25T14:03:41.031729Z","iopub.status.idle":"2023-01-25T14:03:41.132070Z","shell.execute_reply.started":"2023-01-25T14:03:41.031692Z","shell.execute_reply":"2023-01-25T14:03:41.131078Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"there was a method called Reset in class LMModel3 which set h=0 to start clean for the next epoch. This is called via callBack","metadata":{}},{"cell_type":"code","source":"learn = Learner(dls,LMModel3(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy, cbs=ModelResetter)\nlearn.fit_one_cycle(10,3e-3)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:03:41.136709Z","iopub.execute_input":"2023-01-25T14:03:41.137371Z","iopub.status.idle":"2023-01-25T14:04:03.889193Z","shell.execute_reply.started":"2023-01-25T14:03:41.137327Z","shell.execute_reply":"2023-01-25T14:04:03.887955Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.681793</td>\n      <td>1.890971</td>\n      <td>0.406490</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.345999</td>\n      <td>1.785482</td>\n      <td>0.442788</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.112991</td>\n      <td>1.656702</td>\n      <td>0.471635</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.007225</td>\n      <td>1.471269</td>\n      <td>0.542548</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.971087</td>\n      <td>1.537394</td>\n      <td>0.563462</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.921116</td>\n      <td>1.647311</td>\n      <td>0.578606</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.875277</td>\n      <td>1.699624</td>\n      <td>0.545913</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.812338</td>\n      <td>1.521746</td>\n      <td>0.614423</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.767454</td>\n      <td>1.545469</td>\n      <td>0.605769</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.746740</td>\n      <td>1.545983</td>\n      <td>0.613462</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"sl = 16\nseqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n         for i in range(0,len(nums)-sl-1,sl))\ncut = int(len(seqs) * 0.8)\ndls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n                             group_chunks(seqs[cut:], bs),\n                             bs=bs, drop_last=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:04:03.891241Z","iopub.execute_input":"2023-01-25T14:04:03.891648Z","iopub.status.idle":"2023-01-25T14:04:04.139130Z","shell.execute_reply.started":"2023-01-25T14:04:03.891603Z","shell.execute_reply":"2023-01-25T14:04:04.138115Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"[L(vocab[o] for o in s) for s in seqs[0]]","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:04:04.141995Z","iopub.execute_input":"2023-01-25T14:04:04.142391Z","iopub.status.idle":"2023-01-25T14:04:04.150972Z","shell.execute_reply.started":"2023-01-25T14:04:04.142353Z","shell.execute_reply":"2023-01-25T14:04:04.149927Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"},"metadata":{}}]},{"cell_type":"code","source":"class LMModel4(Module):\n    def __init__(self, vocab_sz,n_hidden):\n        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n        self.h_h = nn.Linear(n_hidden,n_hidden)\n        self.h_o = nn.Linear(n_hidden,vocab_sz)\n        self.h = 0\n        \n    def forward(self,x):\n        outs = []\n        for i in range(sl):\n            self.h = self.h + self.i_h(x[:,0])\n            self.h = F.relu(self.h_h(self.h))\n            outs.append(self.h_o(self.h))\n        self.h = self.h.detach()\n        return torch.stack(outs, dim=1)\n    \n    def reset(self): self.h = 0\n     \n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:04:04.152387Z","iopub.execute_input":"2023-01-25T14:04:04.152772Z","iopub.status.idle":"2023-01-25T14:04:04.165420Z","shell.execute_reply.started":"2023-01-25T14:04:04.152737Z","shell.execute_reply":"2023-01-25T14:04:04.164241Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"output of size (bsXslXvocab_sz) but learner expects (bsXsl), hence some flattening is to be done)","metadata":{}},{"cell_type":"code","source":"def loss_func(inp,targ):\n    return F.cross_entropy(inp.view(-1,len(vocab)),targ.view(-1))","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:04:04.166787Z","iopub.execute_input":"2023-01-25T14:04:04.167409Z","iopub.status.idle":"2023-01-25T14:04:04.176426Z","shell.execute_reply.started":"2023-01-25T14:04:04.167372Z","shell.execute_reply":"2023-01-25T14:04:04.175251Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n                metrics=accuracy, cbs=ModelResetter)\nlearn.fit_one_cycle(20, 1e-3)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:04:04.178313Z","iopub.execute_input":"2023-01-25T14:04:04.178696Z","iopub.status.idle":"2023-01-25T14:04:21.343567Z","shell.execute_reply.started":"2023-01-25T14:04:04.178660Z","shell.execute_reply":"2023-01-25T14:04:21.342487Z"},"trusted":true},"execution_count":100,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>3.409574</td>\n      <td>3.408678</td>\n      <td>0.025553</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>3.259314</td>\n      <td>3.093459</td>\n      <td>0.137777</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.965466</td>\n      <td>2.808803</td>\n      <td>0.162842</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.811515</td>\n      <td>2.776106</td>\n      <td>0.164225</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.742966</td>\n      <td>2.756315</td>\n      <td>0.167399</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.706500</td>\n      <td>2.737959</td>\n      <td>0.173828</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.674127</td>\n      <td>2.694182</td>\n      <td>0.225098</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.588782</td>\n      <td>2.590155</td>\n      <td>0.282878</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.526418</td>\n      <td>2.587842</td>\n      <td>0.273356</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.459126</td>\n      <td>2.579491</td>\n      <td>0.282389</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.340255</td>\n      <td>2.548283</td>\n      <td>0.294108</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.282141</td>\n      <td>2.428706</td>\n      <td>0.333415</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.228282</td>\n      <td>2.398113</td>\n      <td>0.334635</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.165852</td>\n      <td>2.397338</td>\n      <td>0.344645</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.135190</td>\n      <td>2.402810</td>\n      <td>0.344564</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.115851</td>\n      <td>2.426405</td>\n      <td>0.338216</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.097551</td>\n      <td>2.411240</td>\n      <td>0.342122</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2.081022</td>\n      <td>2.413286</td>\n      <td>0.341064</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2.072026</td>\n      <td>2.417078</td>\n      <td>0.341471</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>2.067762</td>\n      <td>2.416081</td>\n      <td>0.341227</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"Multi-layer RNN:The activations from one layer are passed to another RNN . This way multiple RNNs are stacked on top of each other.\n","metadata":{}},{"cell_type":"code","source":"class LMModel5(Module):\n    def __init__(self, vocab_sz, n_hidden, n_layers):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n        self.h = torch.zeros(n_layers, bs, n_hidden)\n        \n    def forward(self, x):\n        res,h = self.rnn(self.i_h(x), self.h)\n        self.h = h.detach()\n        return self.h_o(res)\n    \n    def reset(self): self.h.zero_()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:04:21.345260Z","iopub.execute_input":"2023-01-25T14:04:21.345638Z","iopub.status.idle":"2023-01-25T14:04:21.353982Z","shell.execute_reply.started":"2023-01-25T14:04:21.345597Z","shell.execute_reply":"2023-01-25T14:04:21.352908Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"We can get better performance with RNNs, if we call detach less often, i.e make the layer deeper and add more layers as well. this poses another problem. the deeper layers mean that there are more matrix multiplications to do. If matrix multipllcations are done with a number greater than 1, it leads to very huge numbers and opposite with numbers less than 1. Exploding or diminishing gradients .\nAlso, weights are usually in floating points - their precision drops with increase in values. This means that weights are either close to zero or go to inf . making the training process useles..\n","metadata":{}},{"cell_type":"markdown","source":"There are some methods to avoid exploding or vanishing gradients - modify the definition of layers like adding batch normalization in convolutional nets or resnets.\nAlso, another method is careful initialization of weights.\nThe problem in RNNs is avoided by introducing two types of layers - LSTM and GRU (Gate Recurrent Unit) and Long Short term memory","metadata":{}},{"cell_type":"markdown","source":"In LSTM, there are two hidden states compared to RNN which had just one hidden state.One for elping the output layer predict the right token given input words and another one for retaining memory of everything happened in the sentence. RNN does not keep track of many previous words.it suffers from very short term memory.","metadata":{}},{"cell_type":"markdown","source":"LSTM uses four neural network layers with sigmoid activation functions and tanh activation functions which squishes output in the range [-1,1]\ntanh(x) = (e^x - e^-x)/(e^x+e^-x). the four nets are called gates.\nthe arrows for input and previous hidden state are joined together in the beginning itself. So, earlier for RNNs the embeddings dimension were different. Now input is n_in+n_hid and output dim is n_hid .this applies to all the nets(gates). \nThe first gate from left to right is called forget gate. it has sigmoid activation function -> so the output is squished between 0 and 1. the result from this gate is multiplied with cell state from previous time step to determine if the values are to be thrown away or not. Values closer to 0 are discarded while values closer to 1 are passed along. \nThis allows LSTM to forget things that are not important, for example if one essay is done, (xxbos encountered), the past could simply be forgotten.\n","metadata":{}},{"cell_type":"markdown","source":"The second gate is called input gate.It works with the third gate to update the cell state.The forget gate may have removed context specific information like gender pronouns which may be needed for better prediction. The input gate works with forget gate to update the cell state.similar to forget gate, input gate decides what words to be updated in the cell state and by what amount is decided by third cell gate(tanh between -1 and 1).\n","metadata":{}},{"cell_type":"markdown","source":"The last gate is the output gate. It determines which information from the cell state to use to generate te output. the cell state goes through tanh to make it between -1 and 1 before combining it with sigmoid output from previous network to generate hidden state at time step t.","metadata":{}},{"cell_type":"code","source":"class LSTMCell(Module):\n    def __init__(self,ni,nh):\n        self.forget_gate = nn.Linear(ni+nh,nh)\n        self.input_gate = nn.Linear(ni+nh, nh)\n        self.cell_gate = nn.Linear(ni+nh,nh)\n        self.output_gate = nn.Linear(ni+nh,nh)\n        \n        \n    def forward(self,input,state):\n        h,c = state\n        h = torch.cat([h,input],dim=1)\n        forget = torch.sigmoid(self.input_gate(h))\n        c = c*forget\n        inp = torch.sigmoid(self.input_gate(h))\n        cell = torch.tanh(self.cell_gate(h))\n        c = c+inp*cell\n        out = torch.sigmoid(self.output_gate(h))\n        h = out*torch.tanh(c)\n        return h,(h,c)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:04:21.355819Z","iopub.execute_input":"2023-01-25T14:04:21.356533Z","iopub.status.idle":"2023-01-25T14:04:21.366945Z","shell.execute_reply.started":"2023-01-25T14:04:21.356495Z","shell.execute_reply":"2023-01-25T14:04:21.365925Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"The code could be refactored. The four networks matrix multiplications could be combined together into one big matrix multiplication as the special fast kernel is to be launched only once on the GPU and parallelization is taken care of by GPU. stacking ni and nh on top of each othre is cumbersome. Hence two separate networks for ni and nh and their results are compared.","metadata":{}},{"cell_type":"code","source":"class LSTMCell(Module):\n    def __init__(self,ni,nh):\n        self.ih = nn.Linear(ni,4*nh)\n        self.hh = nn.Linear(nh,4*nh)\n        \n    def forward(self,input,state):\n        h,c = state\n        gates = (self.ih(input) + self.hh(state)).chunk(4,1) # split the tensor into 4 smaller chunks\n        ingate,forgetgate,outgate = map(torch.sigmoid, gates[:3])\n        cellgate = gates[3].tanh()\n        \n        c = (forgetgate*c + ingate*cellgate)\n        h = outgate*c.tanh()\n        \n        return h,(h,c)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pytorch chunk method working\nt = torch.arange(0,10); t","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:15:15.024987Z","iopub.execute_input":"2023-01-25T14:15:15.025375Z","iopub.status.idle":"2023-01-25T14:15:15.038151Z","shell.execute_reply.started":"2023-01-25T14:15:15.025344Z","shell.execute_reply":"2023-01-25T14:15:15.037044Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"},"metadata":{}}]},{"cell_type":"code","source":"\nt.chunk(2)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:15:22.290563Z","iopub.execute_input":"2023-01-25T14:15:22.291132Z","iopub.status.idle":"2023-01-25T14:15:22.298519Z","shell.execute_reply.started":"2023-01-25T14:15:22.291097Z","shell.execute_reply":"2023-01-25T14:15:22.297412Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"(tensor([0, 1, 2, 3, 4]), tensor([5, 6, 7, 8, 9]))"},"metadata":{}}]},{"cell_type":"code","source":"#To use multi-layer LSTM like RNN, we make use of fastai libraryto do that\nclass LMModel6(Module):\n    def __init__(self,vocab_sz, n_hidden,n_layers):\n        self.i_h = nn.Embedding(vocab_sz,n_hidden)\n        self.rnn = nn.LSTM(n_hidden,n_hidden,n_layers,batch_first=True)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n        self.h = [torch.zeros(n_layers,bs,n_hidden) for _ in range(2)]\n    \n    def forward(self,x):\n        res,h = self.rnn(self.i_h(x),self.h)\n        self.h = [h_.detach() for h_ in h]\n        return self.h_o(res)\n    \n    def reset(self):\n        for h in self.h : h.zero_()\n            \n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:27:08.603076Z","iopub.execute_input":"2023-01-25T14:27:08.603578Z","iopub.status.idle":"2023-01-25T14:27:08.614754Z","shell.execute_reply.started":"2023-01-25T14:27:08.603535Z","shell.execute_reply":"2023-01-25T14:27:08.613706Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"learn = Learner(dls, LMModel6(len(vocab), 64, 2), \n                loss_func=CrossEntropyLossFlat(), \n                metrics=accuracy, cbs=ModelResetter)\nlearn.fit_one_cycle(15, 1e-2)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T14:27:17.859614Z","iopub.execute_input":"2023-01-25T14:27:17.860040Z","iopub.status.idle":"2023-01-25T14:27:44.027740Z","shell.execute_reply.started":"2023-01-25T14:27:17.860002Z","shell.execute_reply":"2023-01-25T14:27:44.026529Z"},"trusted":true},"execution_count":106,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>3.024198</td>\n      <td>2.711789</td>\n      <td>0.295817</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2.156858</td>\n      <td>1.789582</td>\n      <td>0.420898</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.601904</td>\n      <td>1.780979</td>\n      <td>0.493164</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.304933</td>\n      <td>2.122310</td>\n      <td>0.525309</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.043346</td>\n      <td>2.071455</td>\n      <td>0.579183</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.771994</td>\n      <td>1.738052</td>\n      <td>0.677246</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.542696</td>\n      <td>1.463323</td>\n      <td>0.731283</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.357117</td>\n      <td>1.509923</td>\n      <td>0.769287</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.222075</td>\n      <td>1.643330</td>\n      <td>0.803630</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.129873</td>\n      <td>1.521902</td>\n      <td>0.816732</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.080610</td>\n      <td>1.556391</td>\n      <td>0.813477</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.053407</td>\n      <td>1.536389</td>\n      <td>0.818848</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.039203</td>\n      <td>1.524023</td>\n      <td>0.820964</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.032029</td>\n      <td>1.528295</td>\n      <td>0.820394</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.028639</td>\n      <td>1.522395</td>\n      <td>0.820719</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"RNNs are generally hard to train due to the problem of exploding and vanishing gradients.Using LSTM makes it better but it is prone to overfitting .There are techniques to prevent overfitting like regularization, dropout etc. Data Augmentation is hard to do with language models like images. With techniques like dropout, activation regularization and temporal regularization, good performance can be achieved!","metadata":{}},{"cell_type":"markdown","source":"In dropout some activations are zeroed to prevent frauding , to promote cooperation between neurons and to generate noisy activations so that there is good generalization.\nAs far as activation regularization is concerned, it is similar to weight decay. some penalty is added to loss function to reduce the sum squared of weights .\nfor LSTM, the final activations are penalized in the loss function to keep them small enough.\nIn NLP, we are generating tokens in order, meaning that the sentence should make sense when read in order. \n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
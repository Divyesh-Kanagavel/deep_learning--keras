{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwRNontHOUhzPGDJQOH/HB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Divyesh-Kanagavel/deep_learning--keras/blob/master/NN_Intro_AK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sweSpWvfFPbk"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3*x**2 - 4*x + 5"
      ],
      "metadata": {
        "id": "Oa0gapLAx4vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(3.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkWIEWokyAxT",
        "outputId": "170fdce7-901b-43bf-c55f-488e9bcac386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.arange(-5,5,0.25)"
      ],
      "metadata": {
        "id": "253GreSfyFA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ys = f(xs)"
      ],
      "metadata": {
        "id": "XML6eXUYzgrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs,ys)"
      ],
      "metadata": {
        "id": "C8mYjFDkziSy",
        "outputId": "904c68f7-74a6-4ae6-f738-cd7bee0f433d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd29802ec40>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Value:\n",
        "  def __init__(self,data,_children=(), _op='',label=''):\n",
        "    self.data = data\n",
        "    self.grad = 0.0\n",
        "    self._backward = lambda : None   # initially an empty function\n",
        "    self._prev = set(_children)\n",
        "    self._op = _op\n",
        "    self.label=label\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Value(data={self.data})\"\n",
        "\n",
        "  def __add__(self,other):\n",
        "    other=other if isinstance(other,Value) else Value(other)\n",
        "    out =  Value(self.data+other.data, (self,other), '+')\n",
        "    def _backward():\n",
        "      self.grad += 1.0*out.grad\n",
        "      other.grad += 1.0*out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def __radd__(self,other):\n",
        "    return (self+other)\n",
        "\n",
        "  def __sub__(self,other):\n",
        "    return self + (-other)\n",
        "\n",
        "    return out\n",
        "  # a*2.0 is solved with checking the type of other, but 2.0 * a still throws an error - rmul instead of mul fixes this\n",
        "  # rmul will swap the arguments and check if such an overloading exists.\n",
        "  def __rmul__(self,other):\n",
        "    return self*other\n",
        "\n",
        "  def __mul__(self,other):\n",
        "    other=other if isinstance(other,Value) else Value(other)\n",
        "    out = Value(self.data*other.data, (self,other), '*')\n",
        "    def _backward():\n",
        "      self.grad += other.data*out.grad\n",
        "      other.grad += self.data*out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def __neg__(self):\n",
        "    return self * -1\n",
        "\n",
        "  def __pow__(self,other):\n",
        "    assert isinstance(other,(int,float)), \"only supporting int/float powers for now\"\n",
        "    out = Value(self.data**other, (self,), f'**{other}')\n",
        "    def _backward():\n",
        "      self.grad += other*(self.data**(other-1))*out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def __truediv__(self,other):\n",
        "    return self*other**-1\n",
        "\n",
        "  def exp(self):\n",
        "    x = self.data\n",
        "    t = math.exp(x)\n",
        "    out = Value(t,(self,), 'exp')\n",
        "    def _backward():\n",
        "      self.grad+=t*out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def tanh(self):\n",
        "    x = self.data\n",
        "    t = (math.exp(2*x)-1)/(math.exp(2*x)+1)\n",
        "    out = Value(t, (self,),'tanh')\n",
        "    def _backward():\n",
        "      self.grad += (1-t**2)*out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "  def backward(self):\n",
        "    topo = []\n",
        "    visited = set()\n",
        "    def build_topo(v):\n",
        "      if v not in visited:\n",
        "        visited.add(v)\n",
        "        for child in v._prev:\n",
        "          build_topo(child)\n",
        "        topo.append(v)\n",
        "    build_topo(self)\n",
        "    self.grad=1\n",
        "    for node in reversed(topo):\n",
        "      node._backward()\n"
      ],
      "metadata": {
        "id": "YE_PChdDzj_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Value(2.0)\n",
        "b = Value(3.0)\n",
        "a**3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyG0l2anUo6N",
        "outputId": "06034823-8ac9-4949-bbc5-9f530021647c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(data=8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "apart from addition and multiplication, one more operation is required for neural network operations. (Activation functions like tanh, sigmoid etc).\n",
        "To do auto backprop , we need a function in Value class which can map the current grad to previous grad thereby propagating the chain rule useful for backprop.\n",
        "for simple math operations like addition, multiplication, tanh, it is already known.\n",
        "we now have the backward function per node in our neural network which will help us compute gradient of the children. But, we cannot be calling backward individually.so, we sort the neural network graph topologically and then call backward function in the reverse order from the output node o."
      ],
      "metadata": {
        "id": "DPAV5nNqCjsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def trace(root):\n",
        "  # builds a set of all nodes and edges in a graph\n",
        "  nodes, edges = set(), set()\n",
        "  def build(v):\n",
        "    if v not in nodes:\n",
        "      nodes.add(v)\n",
        "      for child in v._prev:\n",
        "        edges.add((child, v))\n",
        "        build(child)\n",
        "  build(root)\n",
        "  return nodes, edges\n",
        "\n",
        "def draw_dot(root):\n",
        "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
        "\n",
        "  nodes, edges = trace(root)\n",
        "  for n in nodes:\n",
        "    uid = str(id(n))\n",
        "    # for any value in the graph, create a rectangular ('record') node for it\n",
        "    dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f  }\" % (n.label, n.data,n.grad), shape='record')\n",
        "    if n._op:\n",
        "      # if this value is a result of some operation, create an op node for it\n",
        "      dot.node(name = uid + n._op, label = n._op)\n",
        "      # and connect this node to it\n",
        "      dot.edge(uid + n._op, uid)\n",
        "\n",
        "  for n1, n2 in edges:\n",
        "    # connect n1 to the op node of n2\n",
        "    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
        "\n",
        "  return dot\n"
      ],
      "metadata": {
        "id": "H0_aJlRxkvDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The micrograd is the class built on top : it works on scalar values. you can add functions which might be included in your neural networks like sigmoid etc.\n",
        "Now , pytorch's autograd is similar to micrograd here but it works on tensors instead of scalar values."
      ],
      "metadata": {
        "id": "iMAHF70lIKbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "9w0o7yiKIgEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.Tensor([2.0]).double()                ; x1.requires_grad = True\n",
        "x2 = torch.Tensor([0.0]).double()                ; x2.requires_grad = True\n",
        "w1 = torch.Tensor([-3.0]).double()               ; w1.requires_grad = True\n",
        "w2 = torch.Tensor([1.0]).double()                ; w2.requires_grad = True\n",
        "b = torch.Tensor([6.8813735870195432]).double()  ; b.requires_grad = True\n",
        "n = x1*w1 + x2*w2 + b\n",
        "o = torch.tanh(n)\n",
        "# by default when you create tensors, they are assumed to be leaf nodes and requires_grad is set to False\n",
        "#so, it is set to true\n",
        "#also, by default the dtype is float32,by casting it to double, it is made float64"
      ],
      "metadata": {
        "id": "IrafRKQqIkdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o.backward()\n",
        "print(f\"Gradient of x1 : {x1.grad.item()}\")\n",
        "print(f\"Gradient of w1 : {w1.grad.item()}\")\n",
        "print(f\"Gradient of x2 : {x2.grad.item()}\")\n",
        "print(f\"Gradient of w2 : {w2.grad.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbR0VpAjI9NW",
        "outputId": "b7d6d22c-0e16-457d-9117-8b292d955e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of x1 : -1.5000003851533106\n",
            "Gradient of w1 : 1.0000002567688737\n",
            "Gradient of x2 : 0.5000001283844369\n",
            "Gradient of w2 : 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "just as we built a micrograd which matches with api of pytorch(pytorch is efficient thanks to parallelization), we will build a neuron, layer and netork similar to how pytorch is built to handle"
      ],
      "metadata": {
        "id": "IzMcwTmlKbfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "Iqi6NHuZK6_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "\n",
        "  def __init__(self, nin):\n",
        "    self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n",
        "    self.b = Value(random.uniform(-1,1))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # w * x + b\n",
        "    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n",
        "    out = act.tanh()\n",
        "    return out\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.w + [self.b]\n",
        "\n"
      ],
      "metadata": {
        "id": "k4FUWeMEI_Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPIk2aKbCsM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "next step is the construction of layer -> since the neuron is already constructed."
      ],
      "metadata": {
        "id": "6RKDrOmHNmzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "\n",
        "  def __init__(self, nin, nout):\n",
        "    self.neurons = [Neuron(nin) for _ in range(nout)]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    outs = [n(x) for n in self.neurons]\n",
        "    return outs[0] if len(outs) == 1 else outs\n",
        "\n",
        "  def parameters(self):\n",
        "    return [p for neuron in self.neurons for p in neuron.parameters()]\n",
        ""
      ],
      "metadata": {
        "id": "xW0DFsx-MpWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "\n",
        "  def __init__(self, nin, nouts):\n",
        "    sz = [nin] + nouts\n",
        "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "  def parameters(self):\n",
        "    return [p for layer in self.layers for p in layer.parameters()]\n"
      ],
      "metadata": {
        "id": "HcSeUtUpQ7tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = MLP(3, [4, 4, 1])"
      ],
      "metadata": {
        "id": "3Hl-Q-V6CJ8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "an example where there are some sample inputs, outputs and loss function to make the neural network trainable."
      ],
      "metadata": {
        "id": "Rf3JQMRoUfRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = [\n",
        "  [2.0, 3.0, -1.0],\n",
        "  [3.0, -1.0, 0.5],\n",
        "  [0.5, 1.0, 1.0],\n",
        "  [1.0, 1.0, -1.0],\n",
        "]\n",
        "ys = [1.0, -1.0, -1.0, 1.0] # desired targets\n"
      ],
      "metadata": {
        "id": "7WGYeyWKUdih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = [n(x) for x in xs]"
      ],
      "metadata": {
        "id": "qTU0PmxxAq3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIvhNd5IBDD3",
        "outputId": "a8262015-0952-4f42-b38a-f87b2ed2da0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Value(data=-0.16405911805550052),\n",
              " Value(data=0.05213921846862931),\n",
              " Value(data=-0.22770039968503053),\n",
              " Value(data=-0.17457404627170683)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss  = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))"
      ],
      "metadata": {
        "id": "ViYsxTWQBESb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss # loss function for the problem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5szs2VPmB0HG",
        "outputId": "a8c444b6-4eae-409c-f6fb-1a2c17e078ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(data=4.43810142818968)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(n.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R57RA17MWUM",
        "outputId": "a0ce02a3-65a5-40f3-eea2-331627cd02de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "ex-wWPTyEIc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7OuwUkAFAvw",
        "outputId": "6a1ec607-6782-4d04-ecf9-1c5d2bc706f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n.layers[0].neurons[0].w[0].grad  # first weight of first neuron for first layer contributes to loss in the following way, ,meaning its increase decreases loss."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODiIcrnIFB6I",
        "outputId": "c12177b4-a466-4dd3-c9c8-f8903672f922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.363820484088941"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD : Backprop learning\n",
        "#Gradient can be though of as vector in the direction of increased loss\n",
        "#Gradient descent\n",
        "for p in n.parameters():\n",
        "  p.data += -0.01*p.grad\n"
      ],
      "metadata": {
        "id": "hLrfRQNyFcMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = [n(x) for x in xs]\n",
        "loss  = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))"
      ],
      "metadata": {
        "id": "FOt_cLzoPlbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbuNkK1UPxi8",
        "outputId": "ff0a0060-4371-4001-b99c-12a17d8dfcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(data=3.4970660684211)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let us do the same for some iterations to check if the loss function converges to zero and the ypred gets closer to ys\n",
        "n = MLP(3, [4, 4, 1])\n",
        "xs = [\n",
        "  [2.0, 3.0, -1.0],\n",
        "  [3.0, -1.0, 0.5],\n",
        "  [0.5, 1.0, 1.0],\n",
        "  [1.0, 1.0, -1.0],\n",
        "]\n",
        "ys = [1.0, -1.0, -1.0, 1.0] # desired targets\n",
        "\n",
        "for i in range(50):\n",
        "  #forward pass\n",
        "  ypred = [n(x) for x in xs]\n",
        "  loss  = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
        "  #backprop\n",
        "  # a subtle and important bug here, before every iteration of backprop, the grads for each parameter must be set to zero,else there will be higher step size and divergence\n",
        "  for p in n.parameters():\n",
        "    p.grad = 0.0\n",
        "  loss.backward()\n",
        "  for p in n.parameters():\n",
        "    p.data += -0.1*p.grad\n",
        "\n",
        "  print(i, loss)\n"
      ],
      "metadata": {
        "id": "O72VzbRtPyKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdee9d1-27e7-4e32-ff65-912f56948fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Value(data=7.00154478653654)\n",
            "1 Value(data=2.547415143939822)\n",
            "2 Value(data=2.3158042033642556)\n",
            "3 Value(data=1.7836034804516105)\n",
            "4 Value(data=0.4066239706984542)\n",
            "5 Value(data=0.08853897943945072)\n",
            "6 Value(data=0.061618721709753375)\n",
            "7 Value(data=0.04773047761272176)\n",
            "8 Value(data=0.03911979476381267)\n",
            "9 Value(data=0.033221658177162536)\n",
            "10 Value(data=0.028915258397032937)\n",
            "11 Value(data=0.02562708123658486)\n",
            "12 Value(data=0.023031396683457814)\n",
            "13 Value(data=0.020928826066877723)\n",
            "14 Value(data=0.01919021724178078)\n",
            "15 Value(data=0.017728100558184814)\n",
            "16 Value(data=0.016481065929752455)\n",
            "17 Value(data=0.015404697921830947)\n",
            "18 Value(data=0.014466059262765951)\n",
            "19 Value(data=0.013640197746703223)\n",
            "20 Value(data=0.012907858669473816)\n",
            "21 Value(data=0.012253942811530433)\n",
            "22 Value(data=0.011666440547892518)\n",
            "23 Value(data=0.011135678655224683)\n",
            "24 Value(data=0.010653777600071546)\n",
            "25 Value(data=0.010214253630998645)\n",
            "26 Value(data=0.009811722451750883)\n",
            "27 Value(data=0.0094416754137844)\n",
            "28 Value(data=0.009100308307393187)\n",
            "29 Value(data=0.008784388855783799)\n",
            "30 Value(data=0.008491153063977838)\n",
            "31 Value(data=0.008218223340870174)\n",
            "32 Value(data=0.00796354323376765)\n",
            "33 Value(data=0.007725324968188021)\n",
            "34 Value(data=0.007502006952147939)\n",
            "35 Value(data=0.007292219102882796)\n",
            "36 Value(data=0.007094754364930884)\n",
            "37 Value(data=0.006908545166238629)\n",
            "38 Value(data=0.006732643840957821)\n",
            "39 Value(data=0.0065662062601377575)\n",
            "40 Value(data=0.006408478073087386)\n",
            "41 Value(data=0.006258783086035288)\n",
            "42 Value(data=0.006116513400380804)\n",
            "43 Value(data=0.005981121007273669)\n",
            "44 Value(data=0.00585211059358238)\n",
            "45 Value(data=0.005729033360307798)\n",
            "46 Value(data=0.005611481690994792)\n",
            "47 Value(data=0.005499084536825752)\n",
            "48 Value(data=0.005391503408458929)\n",
            "49 Value(data=0.005288428883539897)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsVc661Lhb2A",
        "outputId": "8ecaeebd-3e0b-4ad2-9656-d53e54c3681c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Value(data=0.981238774516687),\n",
              " Value(data=-0.954653394861624),\n",
              " Value(data=-0.9500572058171424),\n",
              " Value(data=0.980356985630074)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmtO9hXNhdC-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}